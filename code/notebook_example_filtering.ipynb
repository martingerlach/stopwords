{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat_minor":2,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tutorial for stopword filtering\n\nInteractive notebook for demonstrating filtering","metadata":{}},{"cell_type":"code","source":"## import packages\n\n%load_ext autoreload\n%autoreload 2\n\nimport os,sys\nimport numpy as np\nimport pandas as pd\n\n# display the figure in the notebook\n# %matplotlib inline\n# import matplotlib.pyplot as plt\n# cmap = 'tab10'\n# cm = plt.get_cmap(cmap)\n\n## custom packages\nsrc_dir = os.path.join( 'src')\nsys.path.append(src_dir)\n\nfrom filter_words import run_stopword_statistics\nfrom filter_words import make_stopwords_filter\nfrom filter_words import remove_stopwords_from_list_texts","metadata":{},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1) Load corpus\n\nGet the 20 newsgroup corpus. These are newsarticles from 20 different categories (newsgroups).\n\nWe get a list of documents, where each entry is a list of tokens","metadata":{}},{"cell_type":"code","source":"corpus_name = '20NewsGroup'\nfilename = os.path.join(os.pardir,'data','%s_corpus.csv'%(corpus_name))\ndf = pd.read_csv(filename,index_col=0)\nlist_texts = [  [h.strip() for h in doc.split()  ] for doc in df['text']    ]\nlist_texts[0] ## this is the first doc","metadata":{},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"['new',\n\n 'religion',\n\n 'forming',\n\n 'sign',\n\n 'yawn',\n\n 'the',\n\n 'church',\n\n 'kibology',\n\n 'did',\n\n 'first',\n\n 'and',\n\n 'better']"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2) Get stopword statistics\n\nWe calculate different statistics for each word in order to construct different stopword-filters:\n\n- F, relative frequency\n- I, Information content\n- tfidf, term-frequency-inverse-document-frequency\n- manual, whether the word occurs in the manual stopword list (1), otherwise nan\n\n\n- H, empirical conditional entropy\n- H-tilde, expected conditional entropy from randomized null model\n- N, frequncy (number of counts)\n\n","metadata":{}},{"cell_type":"code","source":"## path to a manual stopword list (this one is from mallet)\npath_stopword_list =  os.path.join(os.pardir,'data','stopword_list_en')\n\n## number of realizations for the random null model\nN_s = 10\n\n## get the statistics\ndf = run_stopword_statistics(list_texts,N_s=N_s,path_stopword_list=path_stopword_list)\n\n## look at the entries\ndf.sort_values(by='F',ascending=False).head()","metadata":{},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/html":"<div>\n\n<style scoped>\n\n    .dataframe tbody tr th:only-of-type {\n\n        vertical-align: middle;\n\n    }\n\n\n\n    .dataframe tbody tr th {\n\n        vertical-align: top;\n\n    }\n\n\n\n    .dataframe thead th {\n\n        text-align: right;\n\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n\n  <thead>\n\n    <tr style=\"text-align: right;\">\n\n      <th></th>\n\n      <th>F</th>\n\n      <th>I</th>\n\n      <th>tfidf</th>\n\n      <th>manual</th>\n\n      <th>H</th>\n\n      <th>H-tilde</th>\n\n      <th>H-tilde_std</th>\n\n      <th>N</th>\n\n    </tr>\n\n  </thead>\n\n  <tbody>\n\n    <tr>\n\n      <th>the</th>\n\n      <td>0.062401</td>\n\n      <td>0.244815</td>\n\n      <td>1.007189</td>\n\n      <td>1.0</td>\n\n      <td>12.982312</td>\n\n      <td>13.227127</td>\n\n      <td>0.004062</td>\n\n      <td>239094</td>\n\n    </tr>\n\n    <tr>\n\n      <th>and</th>\n\n      <td>0.024848</td>\n\n      <td>0.333264</td>\n\n      <td>1.142009</td>\n\n      <td>1.0</td>\n\n      <td>12.800792</td>\n\n      <td>13.134056</td>\n\n      <td>0.003877</td>\n\n      <td>95205</td>\n\n    </tr>\n\n    <tr>\n\n      <th>that</th>\n\n      <td>0.016991</td>\n\n      <td>0.293580</td>\n\n      <td>1.679582</td>\n\n      <td>1.0</td>\n\n      <td>12.764760</td>\n\n      <td>13.058340</td>\n\n      <td>0.007336</td>\n\n      <td>65103</td>\n\n    </tr>\n\n    <tr>\n\n      <th>for</th>\n\n      <td>0.011996</td>\n\n      <td>0.048510</td>\n\n      <td>1.088629</td>\n\n      <td>1.0</td>\n\n      <td>12.916255</td>\n\n      <td>12.964765</td>\n\n      <td>0.010105</td>\n\n      <td>45965</td>\n\n    </tr>\n\n    <tr>\n\n      <th>you</th>\n\n      <td>0.011620</td>\n\n      <td>0.459559</td>\n\n      <td>2.252701</td>\n\n      <td>1.0</td>\n\n      <td>12.497241</td>\n\n      <td>12.956800</td>\n\n      <td>0.005646</td>\n\n      <td>44521</td>\n\n    </tr>\n\n  </tbody>\n\n</table>\n\n</div>","text/plain":"             F         I     tfidf  manual          H    H-tilde  H-tilde_std  \\\n\nthe   0.062401  0.244815  1.007189     1.0  12.982312  13.227127     0.004062   \n\nand   0.024848  0.333264  1.142009     1.0  12.800792  13.134056     0.003877   \n\nthat  0.016991  0.293580  1.679582     1.0  12.764760  13.058340     0.007336   \n\nfor   0.011996  0.048510  1.088629     1.0  12.916255  12.964765     0.010105   \n\nyou   0.011620  0.459559  2.252701     1.0  12.497241  12.956800     0.005646   \n\n\n\n           N  \n\nthe   239094  \n\nand    95205  \n\nthat   65103  \n\nfor    45965  \n\nyou    44521  "},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3)  Construct a stopword filter\n\nWe construct different stopword filters based in different statistics.\n\nFor this we have to specify 3 different components:\n\n- A) method; this specifies the statistic that we use to construct the stopword list. In detail, we define a statistic $S(w)$ and assign words to the stopword list starting from the low-to-high (e.g. $S(w) = F(w)$ assign low-frequency words to the stopword list). Possible options are:\n\n    - 'INFOR',  filter words with high values of Information-content I [S=-I]\n    - 'BOTTOM', filter words with low values of frequency [S = F]\n    - 'TOP', filter words with high values of frequency [S = 1/F]\n    - 'TFIDF', filter words with low values of tfidf [S=tfidf]\n    - 'TFIDF_r', filter words with high values of tfidf [S=-tfidf]\n    - 'MANUAL', filter words from manual stopword list; supply path via path_stopword_list (S = 1 if word is in the list, else it is nan, i.e. cannot be considered for removal.\n        \n        \n- B) cutoff_type [defines the way in which we choose the cutoff]\n\n     - 'p', selects stopword list such that a fraction p of tokens gets removed (approximately)\n     - 'n', selects stopword list such that a number n of types gets removed\n     - 't', selects stopword list such that all words with S<=S_t get removed\n    \n    \n \n- C) cutoff_val [defines the value on which to do the thresholding, see cutoff_type for details]\n\n\n\nBelow you can select different options and inspect the result.\n\nThe resulting dataframe ```df_filter``` contains the words that were assigned to the stopword list based on the selection criteria.","metadata":{}},{"cell_type":"code","source":"## method-options\nmethod = 'INFOR'\n# method = 'BOTTOM'\n# method = 'TOP'\n# method = 'TFIDF'\n# method = 'TFIDF_r'\n# method = 'MANUAL'\n\n\n\n## remove fraction of tokens\ncutoff_type = 'p'\ncutoff_val = 0.5\n\n## remove number of types\n# cutoff_type = 'n'\n# cutoff_val = 10\n\n## remove above a threshold value\n# cutoff_type = 't'\n# cutoff_val = 1\n\ndf_filter = make_stopwords_filter(df,\n                                  method = method,\n                                  cutoff_type = cutoff_type, \n                                  cutoff_val = cutoff_val, )","metadata":{},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_filter","metadata":{},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/html":"<div>\n\n<style scoped>\n\n    .dataframe tbody tr th:only-of-type {\n\n        vertical-align: middle;\n\n    }\n\n\n\n    .dataframe tbody tr th {\n\n        vertical-align: top;\n\n    }\n\n\n\n    .dataframe thead th {\n\n        text-align: right;\n\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n\n  <thead>\n\n    <tr style=\"text-align: right;\">\n\n      <th></th>\n\n      <th>F-cumsum</th>\n\n      <th>S</th>\n\n    </tr>\n\n  </thead>\n\n  <tbody>\n\n    <tr>\n\n      <th>writes</th>\n\n      <td>0.003482</td>\n\n      <td>-0.748533</td>\n\n    </tr>\n\n    <tr>\n\n      <th>article</th>\n\n      <td>0.006477</td>\n\n      <td>-0.613892</td>\n\n    </tr>\n\n    <tr>\n\n      <th>thanks</th>\n\n      <td>0.007250</td>\n\n      <td>-0.383101</td>\n\n    </tr>\n\n    <tr>\n\n      <th>apr</th>\n\n      <td>0.008511</td>\n\n      <td>-0.321539</td>\n\n    </tr>\n\n    <tr>\n\n      <th>anyone</th>\n\n      <td>0.009608</td>\n\n      <td>-0.303154</td>\n\n    </tr>\n\n    <tr>\n\n      <th>appreciated</th>\n\n      <td>0.009783</td>\n\n      <td>-0.131501</td>\n\n    </tr>\n\n    <tr>\n\n      <th>edu</th>\n\n      <td>0.015199</td>\n\n      <td>-0.106187</td>\n\n    </tr>\n\n    <tr>\n\n      <th>wrote</th>\n\n      <td>0.015612</td>\n\n      <td>-0.104174</td>\n\n    </tr>\n\n    <tr>\n\n      <th>just</th>\n\n      <td>0.018056</td>\n\n      <td>-0.101488</td>\n\n    </tr>\n\n    <tr>\n\n      <th>advance</th>\n\n      <td>0.018277</td>\n\n      <td>-0.100900</td>\n\n    </tr>\n\n    <tr>\n\n      <th>abramowitz</th>\n\n      <td>0.018277</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>authoritarianism</th>\n\n      <td>0.018278</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>awvi</th>\n\n      <td>0.018278</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>bmc</th>\n\n      <td>0.018279</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>cgu</th>\n\n      <td>0.018280</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>charlestown</th>\n\n      <td>0.018280</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>closers</th>\n\n      <td>0.018281</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>csw</th>\n\n      <td>0.018281</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>envolvement</th>\n\n      <td>0.018282</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>geographers</th>\n\n      <td>0.018282</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>grog</th>\n\n      <td>0.018283</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>inbfoworld</th>\n\n      <td>0.018283</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>jrgould</th>\n\n      <td>0.018284</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>laval</th>\n\n      <td>0.018284</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>lgsowg</th>\n\n      <td>0.018285</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>massless</th>\n\n      <td>0.018285</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>mcdallas</th>\n\n      <td>0.018286</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>michaelsen</th>\n\n      <td>0.018286</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>muddle</th>\n\n      <td>0.018287</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>naseum</th>\n\n      <td>0.018287</td>\n\n      <td>-0.100000</td>\n\n    </tr>\n\n    <tr>\n\n      <th>...</th>\n\n      <td>...</td>\n\n      <td>...</td>\n\n    </tr>\n\n    <tr>\n\n      <th>sanctified</th>\n\n      <td>0.498610</td>\n\n      <td>0.345455</td>\n\n    </tr>\n\n    <tr>\n\n      <th>thirsty</th>\n\n      <td>0.498612</td>\n\n      <td>0.345455</td>\n\n    </tr>\n\n    <tr>\n\n      <th>wrappers</th>\n\n      <td>0.498615</td>\n\n      <td>0.345455</td>\n\n    </tr>\n\n    <tr>\n\n      <th>comparative</th>\n\n      <td>0.498623</td>\n\n      <td>0.345477</td>\n\n    </tr>\n\n    <tr>\n\n      <th>fundamental</th>\n\n      <td>0.498667</td>\n\n      <td>0.345629</td>\n\n    </tr>\n\n    <tr>\n\n      <th>allan</th>\n\n      <td>0.498690</td>\n\n      <td>0.345664</td>\n\n    </tr>\n\n    <tr>\n\n      <th>qualities</th>\n\n      <td>0.498699</td>\n\n      <td>0.345732</td>\n\n    </tr>\n\n    <tr>\n\n      <th>literature</th>\n\n      <td>0.498752</td>\n\n      <td>0.345932</td>\n\n    </tr>\n\n    <tr>\n\n      <th>lbs</th>\n\n      <td>0.498771</td>\n\n      <td>0.346065</td>\n\n    </tr>\n\n    <tr>\n\n      <th>pissed</th>\n\n      <td>0.498796</td>\n\n      <td>0.346340</td>\n\n    </tr>\n\n    <tr>\n\n      <th>faced</th>\n\n      <td>0.498813</td>\n\n      <td>0.346434</td>\n\n    </tr>\n\n    <tr>\n\n      <th>influence</th>\n\n      <td>0.498849</td>\n\n      <td>0.346457</td>\n\n    </tr>\n\n    <tr>\n\n      <th>ignoring</th>\n\n      <td>0.498876</td>\n\n      <td>0.346458</td>\n\n    </tr>\n\n    <tr>\n\n      <th>pure</th>\n\n      <td>0.498916</td>\n\n      <td>0.346541</td>\n\n    </tr>\n\n    <tr>\n\n      <th>acsu</th>\n\n      <td>0.498941</td>\n\n      <td>0.346894</td>\n\n    </tr>\n\n    <tr>\n\n      <th>using</th>\n\n      <td>0.499739</td>\n\n      <td>0.346912</td>\n\n    </tr>\n\n    <tr>\n\n      <th>combo</th>\n\n      <td>0.499748</td>\n\n      <td>0.347059</td>\n\n    </tr>\n\n    <tr>\n\n      <th>crossed</th>\n\n      <td>0.499757</td>\n\n      <td>0.347059</td>\n\n    </tr>\n\n    <tr>\n\n      <th>penguin</th>\n\n      <td>0.499766</td>\n\n      <td>0.347059</td>\n\n    </tr>\n\n    <tr>\n\n      <th>squeeze</th>\n\n      <td>0.499775</td>\n\n      <td>0.347059</td>\n\n    </tr>\n\n    <tr>\n\n      <th>measured</th>\n\n      <td>0.499796</td>\n\n      <td>0.347130</td>\n\n    </tr>\n\n    <tr>\n\n      <th>leg</th>\n\n      <td>0.499818</td>\n\n      <td>0.347197</td>\n\n    </tr>\n\n    <tr>\n\n      <th>stopped</th>\n\n      <td>0.499883</td>\n\n      <td>0.347276</td>\n\n    </tr>\n\n    <tr>\n\n      <th>postmaster</th>\n\n      <td>0.499893</td>\n\n      <td>0.347283</td>\n\n    </tr>\n\n    <tr>\n\n      <th>followers</th>\n\n      <td>0.499941</td>\n\n      <td>0.347294</td>\n\n    </tr>\n\n    <tr>\n\n      <th>scriptural</th>\n\n      <td>0.499951</td>\n\n      <td>0.347368</td>\n\n    </tr>\n\n    <tr>\n\n      <th>omitted</th>\n\n      <td>0.499965</td>\n\n      <td>0.347397</td>\n\n    </tr>\n\n    <tr>\n\n      <th>sounding</th>\n\n      <td>0.499980</td>\n\n      <td>0.347498</td>\n\n    </tr>\n\n    <tr>\n\n      <th>chassis</th>\n\n      <td>0.499988</td>\n\n      <td>0.347565</td>\n\n    </tr>\n\n    <tr>\n\n      <th>positioning</th>\n\n      <td>0.499996</td>\n\n      <td>0.347641</td>\n\n    </tr>\n\n  </tbody>\n\n</table>\n\n<p>66771 rows × 2 columns</p>\n\n</div>","text/plain":"                  F-cumsum         S\n\nwrites            0.003482 -0.748533\n\narticle           0.006477 -0.613892\n\nthanks            0.007250 -0.383101\n\napr               0.008511 -0.321539\n\nanyone            0.009608 -0.303154\n\nappreciated       0.009783 -0.131501\n\nedu               0.015199 -0.106187\n\nwrote             0.015612 -0.104174\n\njust              0.018056 -0.101488\n\nadvance           0.018277 -0.100900\n\nabramowitz        0.018277 -0.100000\n\nauthoritarianism  0.018278 -0.100000\n\nawvi              0.018278 -0.100000\n\nbmc               0.018279 -0.100000\n\ncgu               0.018280 -0.100000\n\ncharlestown       0.018280 -0.100000\n\nclosers           0.018281 -0.100000\n\ncsw               0.018281 -0.100000\n\nenvolvement       0.018282 -0.100000\n\ngeographers       0.018282 -0.100000\n\ngrog              0.018283 -0.100000\n\ninbfoworld        0.018283 -0.100000\n\njrgould           0.018284 -0.100000\n\nlaval             0.018284 -0.100000\n\nlgsowg            0.018285 -0.100000\n\nmassless          0.018285 -0.100000\n\nmcdallas          0.018286 -0.100000\n\nmichaelsen        0.018286 -0.100000\n\nmuddle            0.018287 -0.100000\n\nnaseum            0.018287 -0.100000\n\n...                    ...       ...\n\nsanctified        0.498610  0.345455\n\nthirsty           0.498612  0.345455\n\nwrappers          0.498615  0.345455\n\ncomparative       0.498623  0.345477\n\nfundamental       0.498667  0.345629\n\nallan             0.498690  0.345664\n\nqualities         0.498699  0.345732\n\nliterature        0.498752  0.345932\n\nlbs               0.498771  0.346065\n\npissed            0.498796  0.346340\n\nfaced             0.498813  0.346434\n\ninfluence         0.498849  0.346457\n\nignoring          0.498876  0.346458\n\npure              0.498916  0.346541\n\nacsu              0.498941  0.346894\n\nusing             0.499739  0.346912\n\ncombo             0.499748  0.347059\n\ncrossed           0.499757  0.347059\n\npenguin           0.499766  0.347059\n\nsqueeze           0.499775  0.347059\n\nmeasured          0.499796  0.347130\n\nleg               0.499818  0.347197\n\nstopped           0.499883  0.347276\n\npostmaster        0.499893  0.347283\n\nfollowers         0.499941  0.347294\n\nscriptural        0.499951  0.347368\n\nomitted           0.499965  0.347397\n\nsounding          0.499980  0.347498\n\nchassis           0.499988  0.347565\n\npositioning       0.499996  0.347641\n\n\n\n[66771 rows x 2 columns]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4) Apply the stopword-filter to remove the words from the list of texts\n\nWe inspect one particular document for the effect of the stopword filter.\n\nWe report the remaining faction of tokens in the filtered list of texts.","metadata":{}},{"cell_type":"code","source":"## get the list of words from df_filter and get a filtered list_of_texts\nlist_words_filter = list(df_filter.index)\nlist_texts_filter = remove_stopwords_from_list_texts(list_texts, list_words_filter)\n\nprint('Original text:', list_texts[0])\nprint('Filtered text:', list_texts_filter[0])\nN = sum([ len(doc) for doc in list_texts ])\nN_filter = sum([ len(doc) for doc in list_texts_filter ])\nprint('Remaining fraction of tokens',N_filter/N)","metadata":{},"execution_count":6,"outputs":[{"name":"stdout","output_type":"stream","text":"Original text: ['new', 'religion', 'forming', 'sign', 'yawn', 'the', 'church', 'kibology', 'did', 'first', 'and', 'better']\n\nFiltered text: ['new', 'religion', 'sign', 'church', 'kibology', 'did', 'first']\n\nRemaining fraction of tokens 0.5000040453507306\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}