{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for stopword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import packages\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# display the figure in the notebook\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# cmap = 'tab10'\n",
    "# cm = plt.get_cmap(cmap)\n",
    "\n",
    "## custom packages\n",
    "src_dir = os.path.join( 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "from filter_words import run_stopword_statistics\n",
    "from filter_words import make_stopwords_filter\n",
    "from filter_words import remove_stopwords_from_list_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load corpus\n",
    "\n",
    "Get the 20 newsgroup corpus. These are newsarticles from 20 different categories (newsgroups).\n",
    "\n",
    "We get a list of documents, where each entry is a list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'religion',\n",
       " 'forming',\n",
       " 'sign',\n",
       " 'yawn',\n",
       " 'the',\n",
       " 'church',\n",
       " 'kibology',\n",
       " 'did',\n",
       " 'first',\n",
       " 'and',\n",
       " 'better']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_name = '20NewsGroup'\n",
    "filename = os.path.join(os.pardir,'data','%s_corpus.csv'%(corpus_name))\n",
    "df = pd.read_csv(filename,index_col=0)\n",
    "list_texts = [  [h.strip() for h in doc.split()  ] for doc in df['text']    ]\n",
    "list_texts[0] ## this is the first doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Get stopword statistics\n",
    "\n",
    "We calculate different statistics for each word in order to construct different stopword-filters:\n",
    "\n",
    "- F, relative frequency\n",
    "- I, Information content\n",
    "- tfidf, term-frequency-inverse-document-frequency\n",
    "- manual, whether the word occurs in the manual stopword list (1), otherwise nan\n",
    "\n",
    "\n",
    "- H, empirical conditional entropy\n",
    "- H-tilde, expected conditional entropy from randomized null model\n",
    "- N, frequncy (number of counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>manual</th>\n",
       "      <th>H</th>\n",
       "      <th>H-tilde</th>\n",
       "      <th>H-tilde_std</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>0.062401</td>\n",
       "      <td>0.243209</td>\n",
       "      <td>1.007189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.982312</td>\n",
       "      <td>13.225522</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>239094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0.024848</td>\n",
       "      <td>0.329145</td>\n",
       "      <td>1.142009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.800792</td>\n",
       "      <td>13.129937</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>95205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>0.016991</td>\n",
       "      <td>0.294637</td>\n",
       "      <td>1.679582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.764760</td>\n",
       "      <td>13.059397</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>65103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.011996</td>\n",
       "      <td>0.050401</td>\n",
       "      <td>1.088629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.916255</td>\n",
       "      <td>12.966657</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>45965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.456796</td>\n",
       "      <td>2.252701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.497241</td>\n",
       "      <td>12.954036</td>\n",
       "      <td>0.010503</td>\n",
       "      <td>44521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             F         I     tfidf  manual          H    H-tilde  H-tilde_std  \\\n",
       "the   0.062401  0.243209  1.007189     1.0  12.982312  13.225522     0.003533   \n",
       "and   0.024848  0.329145  1.142009     1.0  12.800792  13.129937     0.006665   \n",
       "that  0.016991  0.294637  1.679582     1.0  12.764760  13.059397     0.007979   \n",
       "for   0.011996  0.050401  1.088629     1.0  12.916255  12.966657     0.007477   \n",
       "you   0.011620  0.456796  2.252701     1.0  12.497241  12.954036     0.010503   \n",
       "\n",
       "           N  \n",
       "the   239094  \n",
       "and    95205  \n",
       "that   65103  \n",
       "for    45965  \n",
       "you    44521  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## path to a manual stopword list (this one is from mallet)\n",
    "path_stopword_list =  os.path.join(os.pardir,'data','stopword_list_en')\n",
    "\n",
    "## number of realizations for the random null model\n",
    "N_s = 10\n",
    "\n",
    "## get the statistics\n",
    "df = run_stopword_statistics(list_texts,N_s=N_s,path_stopword_list=path_stopword_list)\n",
    "\n",
    "## look at the entries\n",
    "df.sort_values(by='F',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3)  Construct a stopword filter\n",
    "\n",
    "We construct different stopword filters based in different statistics.\n",
    "\n",
    "For this we have to specify 3 different components:\n",
    "\n",
    "- A) method; this specifies the statistic that we use to construct the stopword list. In detail, we define a statistic $S(w)$ and assign words to the stopword list starting from the low-to-high (e.g. $S(w) = F(w)$ assign low-frequency words to the stopword list). Possible options are:\n",
    "\n",
    "    - 'INFOR',  filter words with high values of Information-content I [S=-I]\n",
    "    - 'BOTTOM', filter words with low values of frequency [S = F]\n",
    "    - 'TOP', filter words with high values of frequency [S = 1/F]\n",
    "    - 'TFIDF', filter words with low values of tfidf [S=tfidf]\n",
    "    - 'TFIDF_r', filter words with high values of tfidf [S=-tfidf]\n",
    "    - 'MANUAL', filter words from manual stopword list; supply path via path_stopword_list (S = 1 if word is in the list, else it is nan, i.e. cannot be considered for removal.\n",
    "        \n",
    "        \n",
    "- B) cutoff_type [defines the way in which we choose the cutoff]\n",
    "\n",
    "     - 'p', selects stopword list such that a fraction p of tokens gets removed (approximately)\n",
    "     - 'n', selects stopword list such that a number n of types gets removed\n",
    "     - 't', selects stopword list such that all words with S<=S_t get removed\n",
    "    \n",
    "    \n",
    " \n",
    "- C) cutoff_val [defines the value on which to do the thresholding, see cutoff_type for details]\n",
    "\n",
    "\n",
    "\n",
    "Below you can select different options and inspect the result.\n",
    "\n",
    "The resulting dataframe ```df_filter``` contains the words that were assigned to the stopword list based on the selection criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## method-options\n",
    "method = 'INFOR'\n",
    "# method = 'BOTTOM'\n",
    "# method = 'TOP'\n",
    "# method = 'TFIDF'\n",
    "# method = 'TFIDF_r'\n",
    "# method = 'MANUAL'\n",
    "\n",
    "\n",
    "\n",
    "## remove fraction of tokens\n",
    "cutoff_type = 'p'\n",
    "cutoff_val = 0.5\n",
    "\n",
    "## remove number of types\n",
    "# cutoff_type = 'n'\n",
    "# cutoff_val = 10\n",
    "\n",
    "## remove above a threshold value\n",
    "# cutoff_type = 't'\n",
    "# cutoff_val = 1\n",
    "\n",
    "df_filter = make_stopwords_filter(df,\n",
    "                                  method = method,\n",
    "                                  cutoff_type = cutoff_type, \n",
    "                                  cutoff_val = cutoff_val, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F-cumsum</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>writes</th>\n",
       "      <td>0.003482</td>\n",
       "      <td>-0.745709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article</th>\n",
       "      <td>0.006477</td>\n",
       "      <td>-0.610946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thanks</th>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.386810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apr</th>\n",
       "      <td>0.008511</td>\n",
       "      <td>-0.324651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anyone</th>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.304057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advance</th>\n",
       "      <td>0.009829</td>\n",
       "      <td>-0.127854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appreciated</th>\n",
       "      <td>0.010004</td>\n",
       "      <td>-0.121756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uhim</th>\n",
       "      <td>0.010005</td>\n",
       "      <td>-0.118872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edu</th>\n",
       "      <td>0.015421</td>\n",
       "      <td>-0.108703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrote</th>\n",
       "      <td>0.015835</td>\n",
       "      <td>-0.105345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>berate</th>\n",
       "      <td>0.015835</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>byline</th>\n",
       "      <td>0.015836</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canadarms</th>\n",
       "      <td>0.015836</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cartlidge</th>\n",
       "      <td>0.015837</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>castigate</th>\n",
       "      <td>0.015837</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>caverns</th>\n",
       "      <td>0.015838</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commandline</th>\n",
       "      <td>0.015838</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concious</th>\n",
       "      <td>0.015839</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conquests</th>\n",
       "      <td>0.015839</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crabby</th>\n",
       "      <td>0.015840</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>csissun</th>\n",
       "      <td>0.015840</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddepth</th>\n",
       "      <td>0.015841</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deportees</th>\n",
       "      <td>0.015841</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dismissively</th>\n",
       "      <td>0.015842</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emik</th>\n",
       "      <td>0.015842</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>getters</th>\n",
       "      <td>0.015843</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>grc</th>\n",
       "      <td>0.015843</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heavylift</th>\n",
       "      <td>0.015844</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icdmnet</th>\n",
       "      <td>0.015844</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insomina</th>\n",
       "      <td>0.015845</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transformers</th>\n",
       "      <td>0.499286</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advent</th>\n",
       "      <td>0.499288</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cfaehl</th>\n",
       "      <td>0.499291</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chat</th>\n",
       "      <td>0.499294</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hippo</th>\n",
       "      <td>0.499297</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ipp</th>\n",
       "      <td>0.499300</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mikes</th>\n",
       "      <td>0.499303</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nynexst</th>\n",
       "      <td>0.499306</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obscured</th>\n",
       "      <td>0.499309</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propagandist</th>\n",
       "      <td>0.499311</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scooter</th>\n",
       "      <td>0.499314</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shirley</th>\n",
       "      <td>0.499317</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stevethc</th>\n",
       "      <td>0.499320</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tirade</th>\n",
       "      <td>0.499323</td>\n",
       "      <td>0.345455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharing</th>\n",
       "      <td>0.499348</td>\n",
       "      <td>0.345624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>0.499462</td>\n",
       "      <td>0.345628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allan</th>\n",
       "      <td>0.499486</td>\n",
       "      <td>0.345664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debt</th>\n",
       "      <td>0.499501</td>\n",
       "      <td>0.345942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>officially</th>\n",
       "      <td>0.499526</td>\n",
       "      <td>0.345944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scenario</th>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phrase</th>\n",
       "      <td>0.499591</td>\n",
       "      <td>0.346342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stands</th>\n",
       "      <td>0.499639</td>\n",
       "      <td>0.346501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pure</th>\n",
       "      <td>0.499679</td>\n",
       "      <td>0.346541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chapel</th>\n",
       "      <td>0.499690</td>\n",
       "      <td>0.346667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objectivity</th>\n",
       "      <td>0.499698</td>\n",
       "      <td>0.346932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>further</th>\n",
       "      <td>0.499878</td>\n",
       "      <td>0.347203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offices</th>\n",
       "      <td>0.499897</td>\n",
       "      <td>0.347222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>realistic</th>\n",
       "      <td>0.499918</td>\n",
       "      <td>0.347315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>steady</th>\n",
       "      <td>0.499931</td>\n",
       "      <td>0.347330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>depressed</th>\n",
       "      <td>0.499941</td>\n",
       "      <td>0.347368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66774 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              F-cumsum         S\n",
       "writes        0.003482 -0.745709\n",
       "article       0.006477 -0.610946\n",
       "thanks        0.007250 -0.386810\n",
       "apr           0.008511 -0.324651\n",
       "anyone        0.009608 -0.304057\n",
       "advance       0.009829 -0.127854\n",
       "appreciated   0.010004 -0.121756\n",
       "uhim          0.010005 -0.118872\n",
       "edu           0.015421 -0.108703\n",
       "wrote         0.015835 -0.105345\n",
       "berate        0.015835 -0.100000\n",
       "byline        0.015836 -0.100000\n",
       "canadarms     0.015836 -0.100000\n",
       "cartlidge     0.015837 -0.100000\n",
       "castigate     0.015837 -0.100000\n",
       "caverns       0.015838 -0.100000\n",
       "commandline   0.015838 -0.100000\n",
       "concious      0.015839 -0.100000\n",
       "conquests     0.015839 -0.100000\n",
       "crabby        0.015840 -0.100000\n",
       "csissun       0.015840 -0.100000\n",
       "ddepth        0.015841 -0.100000\n",
       "deportees     0.015841 -0.100000\n",
       "dismissively  0.015842 -0.100000\n",
       "emik          0.015842 -0.100000\n",
       "getters       0.015843 -0.100000\n",
       "grc           0.015843 -0.100000\n",
       "heavylift     0.015844 -0.100000\n",
       "icdmnet       0.015844 -0.100000\n",
       "insomina      0.015845 -0.100000\n",
       "...                ...       ...\n",
       "transformers  0.499286  0.345455\n",
       "advent        0.499288  0.345455\n",
       "cfaehl        0.499291  0.345455\n",
       "chat          0.499294  0.345455\n",
       "hippo         0.499297  0.345455\n",
       "ipp           0.499300  0.345455\n",
       "mikes         0.499303  0.345455\n",
       "nynexst       0.499306  0.345455\n",
       "obscured      0.499309  0.345455\n",
       "propagandist  0.499311  0.345455\n",
       "scooter       0.499314  0.345455\n",
       "shirley       0.499317  0.345455\n",
       "stevethc      0.499320  0.345455\n",
       "tirade        0.499323  0.345455\n",
       "sharing       0.499348  0.345624\n",
       "choose        0.499462  0.345628\n",
       "allan         0.499486  0.345664\n",
       "debt          0.499501  0.345942\n",
       "officially    0.499526  0.345944\n",
       "scenario      0.499546  0.346154\n",
       "phrase        0.499591  0.346342\n",
       "stands        0.499639  0.346501\n",
       "pure          0.499679  0.346541\n",
       "chapel        0.499690  0.346667\n",
       "objectivity   0.499698  0.346932\n",
       "further       0.499878  0.347203\n",
       "offices       0.499897  0.347222\n",
       "realistic     0.499918  0.347315\n",
       "steady        0.499931  0.347330\n",
       "depressed     0.499941  0.347368\n",
       "\n",
       "[66774 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Apply the stopword-filter to remove the words from the list of texts\n",
    "\n",
    "We inspect one particular document for the effect of the stopword filter.\n",
    "\n",
    "We report the remaining faction of tokens in the filtered list of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: ['new', 'religion', 'forming', 'sign', 'yawn', 'the', 'church', 'kibology', 'did', 'first', 'and', 'better']\n",
      "Filtered text: ['new', 'religion', 'sign', 'church', 'kibology', 'did', 'first']\n",
      "Remaining fraction of tokens 0.5000593753091105\n"
     ]
    }
   ],
   "source": [
    "## get the list of words from df_filter and get a filtered list_of_texts\n",
    "list_words_filter = list(df_filter.index)\n",
    "list_texts_filter = remove_stopwords_from_list_texts(list_texts, list_words_filter)\n",
    "\n",
    "print('Original text:', list_texts[0])\n",
    "print('Filtered text:', list_texts_filter[0])\n",
    "N = sum([ len(doc) for doc in list_texts ])\n",
    "N_filter = sum([ len(doc) for doc in list_texts_filter ])\n",
    "print('Remaining fraction of tokens',N_filter/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
